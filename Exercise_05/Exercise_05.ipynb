{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "## Introduction to  Bilinear RESCAL\n",
    "\n",
    "In this exercise we will implement Bilinear RESCAL using pytorch. For introduction to pytorch please refer to the [Introduction-to-Pytorch.ipynb](https://github.com/SmartDataAnalytics/Knowledge-Graph-Analysis-Programming-Exercises/blob/master/Exercise_05/Introduction-to-Pytorch.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescal Bilinear Model\n",
    "In last exercise we used alternating least square method for the implementation RESCAL. In this one we will see how we can solve the same optimization problem using SGD.\n",
    " \n",
    "In last exercise we saw for RESCAL we can set loss function:\n",
    "\n",
    "$L_{ijk} = argmin_{A,R} \\sum_k||T_{ijk}-a_{i} R_{:,:,k} a{j}^T||^2 $\n",
    "\n",
    "With SGD we will use a slightly different loss function defined as:\n",
    "\n",
    "$L_{ijk} = x_{ijk} log \\sigma (a_{i} R_{:,:,k} a{j}^T) + (1-x_{ijk}) log \\sigma (1 - a_{i} R_{:,:,k} a{j}^T)$\n",
    "\n",
    "where $x_{ijk}=1$ if triple $(e_i,r_k,e_j)$ exists and $x_{ijk} = 0$ otherwise.\n",
    "\n",
    "We can see above formulation of loss function is an analogue to a classification problem. For evaluations of method we will use kinship dataset representing 26 relations (brother, sister, father,...} between 104 people. \n",
    "Let's proceed with the implementation of our first model using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Some libraries to import\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "from torch.autograd import Variable\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some Utilities\n",
    "def get_minibatches(X, mb_size, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate minibatches from given dataset for training.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    X: np.array of M x 3\n",
    "        Contains the triplets from dataset. The entities and relations are\n",
    "        translated to its unique indices.\n",
    "\n",
    "    mb_size: int\n",
    "        Size of each minibatch.\n",
    "\n",
    "    shuffle: bool, default True\n",
    "        Whether to shuffle the dataset before dividing it into minibatches.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mb_iter: generator\n",
    "        Example usage:\n",
    "        --------------\n",
    "        mb_iter = get_minibatches(X_train, mb_size)\n",
    "        for X_mb in mb_iter:\n",
    "            // do something with X_mb, the minibatch\n",
    "    \"\"\"\n",
    "    minibatches = []\n",
    "    X_shuff = np.copy(X)\n",
    "\n",
    "    if shuffle:\n",
    "        X_shuff = skshuffle(X_shuff)\n",
    "\n",
    "    for i in range(0, X_shuff.shape[0], mb_size):\n",
    "        yield X_shuff[i:i + mb_size]\n",
    "\n",
    "def sample_negatives(X, n_e):\n",
    "    \"\"\"\n",
    "    Perform negative sampling by corrupting head or tail of each triplets in\n",
    "    dataset.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    X: int matrix of M x 3, where M is the (mini)batch size\n",
    "        First column contains index of head entities.\n",
    "        Second column contains index of relationships.\n",
    "        Third column contains index of tail entities.\n",
    "\n",
    "    n_e: int\n",
    "        Number of entities in dataset.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    X_corr: int matrix of M x 3, where M is the (mini)batch size\n",
    "        Similar to input param X, but at each column, either first or third col\n",
    "        is subtituted with random entity.\n",
    "    \"\"\"\n",
    "    M = X.shape[0]\n",
    "\n",
    "    corr = np.random.randint(n_e, size=M)\n",
    "    e_idxs = np.random.choice([0, 2], size=M)\n",
    "\n",
    "    X_corr = np.copy(X)\n",
    "    X_corr[np.arange(M), e_idxs] = corr\n",
    "\n",
    "    return X_corr\n",
    "\n",
    "def accuracy(y_pred, y_true, thresh=0.5, reverse=False):\n",
    "    \"\"\"\n",
    "    Compute accuracy score.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    y_pred: np.array\n",
    "        Predicted (Bernoulli) probabilities.\n",
    "\n",
    "    y_true: np.array, binary\n",
    "        True (Bernoulli) labels.\n",
    "\n",
    "    thresh: float, default: 0.5\n",
    "        Classification threshold.\n",
    "\n",
    "    reverse: bool, default: False\n",
    "        If it is True, then classify (y <= thresh) to be 1.\n",
    "    \"\"\"\n",
    "    y = (y_pred >= thresh) if not reverse else (y_pred <= thresh)\n",
    "    return np.mean(y == y_true)\n",
    "\n",
    "def auc(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Compute area under ROC curve score.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    y_pred: np.array\n",
    "        Predicted (Bernoulli) probabilities.\n",
    "\n",
    "    y_true: np.array, binary\n",
    "        True (Bernoulli) labels.\n",
    "    \"\"\"\n",
    "    return roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RESCAL(nn.Module):\n",
    "    \"\"\"\n",
    "    RESCAL: bilinear model\n",
    "    ----------------------\n",
    "    Nickel, Maximilian, Volker Tresp, and Hans-Peter Kriegel.\n",
    "    \"A three-way model for collective learning on multi-relational data.\"\n",
    "    ICML. 2011.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_e, n_r, k, lam, gpu=False):\n",
    "        \"\"\"\n",
    "        RESCAL: bilinear model\n",
    "        ----------------------\n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "            n_e: int\n",
    "                Number of entities in dataset.\n",
    "\n",
    "            n_r: int\n",
    "                Number of relationships in dataset.\n",
    "\n",
    "            k: int\n",
    "                Embedding size.\n",
    "\n",
    "            lam: float\n",
    "                Prior strength of the embeddings. Used to constaint the\n",
    "                embedding norms inside a (euclidean) unit ball. The prior is\n",
    "                Gaussian, this param is the precision.\n",
    "\n",
    "            gpu: bool, default: False\n",
    "                Whether to use GPU or not.\n",
    "        \"\"\"\n",
    "        super(RESCAL, self).__init__()\n",
    "        self.gpu = gpu\n",
    "        # Hyperparams\n",
    "        self.n_e = n_e\n",
    "        self.n_r = n_r\n",
    "        self.k = k\n",
    "        self.lam = lam\n",
    "\n",
    "        # Nets\n",
    "        self.emb_E = nn.Embedding(self.n_e, self.k)\n",
    "        self.emb_R = nn.Embedding(self.n_r, self.k**2)\n",
    "\n",
    "        self.embeddings = [self.emb_E, self.emb_R]\n",
    "        self.initialize_embeddings()\n",
    "\n",
    "        # Copy all params to GPU if specified\n",
    "        if self.gpu:\n",
    "            self.cuda()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Decompose X into head, relationship, tail\n",
    "        hs, ls, ts = X[:, 0], X[:, 1], X[:, 2]\n",
    "\n",
    "        if self.gpu:\n",
    "            hs = Variable(torch.from_numpy(hs).cuda())\n",
    "            ls = Variable(torch.from_numpy(ls).cuda())\n",
    "            ts = Variable(torch.from_numpy(ts).cuda())\n",
    "        else:\n",
    "            hs = Variable(torch.from_numpy(hs))\n",
    "            ls = Variable(torch.from_numpy(ls))\n",
    "            ts = Variable(torch.from_numpy(ts))\n",
    "\n",
    "        # Project to embedding, each is M x k\n",
    "        e_hs = self.emb_E(hs).view(-1, self.k, 1)\n",
    "        e_ts = self.emb_E(ts).view(-1, self.k, 1)\n",
    "        W = self.emb_R(ls).view(-1, self.k, self.k)  # M x k x k\n",
    "\n",
    "        # Forward\n",
    "        out = torch.bmm(torch.transpose(e_hs, 1, 2), W)  # h^T W\n",
    "        out = torch.bmm(out, e_ts)  # (h^T W) h\n",
    "        out = out.view(-1, 1)  # [-1, 1, 1] -> [-1, 1]\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def log_loss(self, y_pred, y_true, average=True):\n",
    "        \"\"\"\n",
    "        Compute log loss (Bernoulli NLL).\n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "        y_pred: vector of size Mx1\n",
    "            Contains prediction logits.\n",
    "\n",
    "        y_true: np.array of size Mx1 (binary)\n",
    "            Contains the true labels.\n",
    "\n",
    "        average: bool, default: True\n",
    "            Whether to average the loss or just summing it.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        loss: float\n",
    "        \"\"\"\n",
    "        if self.gpu:\n",
    "            y_true = Variable(torch.from_numpy(y_true.astype(np.float32)).cuda())\n",
    "        else:\n",
    "            y_true = Variable(torch.from_numpy(y_true.astype(np.float32)))\n",
    "\n",
    "        nll = F.binary_cross_entropy_with_logits(y_pred, y_true, size_average=average)\n",
    "\n",
    "        norm_E = torch.norm(self.emb_E.weight, 2, 1)\n",
    "        norm_R = torch.norm(self.emb_R.weight, 2, 1)\n",
    "\n",
    "        # Penalize when embeddings norms larger than one\n",
    "        nlp1 = torch.sum(torch.clamp(norm_E - 1, min=0))\n",
    "        nlp2 = torch.sum(torch.clamp(norm_R - 1, min=0))\n",
    "\n",
    "        if average:\n",
    "            nlp1 /= nlp1.size(0)\n",
    "            nlp2 /= nlp2.size(0)\n",
    "\n",
    "        return nll + self.lam*nlp1 + self.lam*nlp2  \n",
    "    \n",
    "    def predict(self, X, sigmoid=False):\n",
    "        \"\"\"\n",
    "        Predict the score of test batch.\n",
    "\n",
    "        Params:\n",
    "        -------\n",
    "        X: int matrix of M x 3, where M is the (mini)batch size\n",
    "            First row contains index of head entities.\n",
    "            Second row contains index of relationships.\n",
    "            Third row contains index of tail entities.\n",
    "\n",
    "        sigmoid: bool, default: False\n",
    "            Whether to apply sigmoid at the prediction or not. Useful if the\n",
    "            predicted result is scores/logits.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred: np.array of Mx1\n",
    "        \"\"\"\n",
    "        y_pred = self.forward(X).view(-1, 1)\n",
    "\n",
    "        if sigmoid:\n",
    "            y_pred = F.sigmoid(y_pred)\n",
    "\n",
    "        if self.gpu:\n",
    "            return y_pred.cpu().data.numpy()\n",
    "        else:\n",
    "            return y_pred.data.numpy()\n",
    "        \n",
    "    def normalize_embeddings(self):\n",
    "        for e in self.embeddings:\n",
    "            e.weight.data.renorm_(p=2, dim=0, maxnorm=1)\n",
    "            \n",
    "    def initialize_embeddings(self):\n",
    "        r = 6/np.sqrt(self.k)\n",
    "        for e in self.embeddings:\n",
    "            e.weight.data.uniform_(-r, r)\n",
    "\n",
    "        self.normalize_embeddings()\n",
    "    \n",
    "    def get_embeddings(self):\n",
    "        entity_embedding = self.embeddings[0].weight.data.numpy()\n",
    "        relation_embedding = self.embeddings[1].weight.data.numpy()\n",
    "        return entity_embedding, relation_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6820080150>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "randseed = 9999\n",
    "np.random.seed(randseed)\n",
    "torch.manual_seed(randseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "# Load dictionary lookups\n",
    "idx2ent = np.load('data/kinship/bin/idx2ent.npy')\n",
    "idx2rel = np.load('data/kinship/bin/idx2rel.npy')\n",
    "\n",
    "n_e = len(idx2ent)\n",
    "n_r = len(idx2rel)\n",
    "\n",
    "# Load dataset\n",
    "X_train = np.load('data/kinship/bin/train.npy')\n",
    "X_val = np.load('data/kinship/bin/val.npy')\n",
    "y_val = np.load('data/kinship/bin/y_val.npy')\n",
    "\n",
    "X_val_pos = X_val[y_val.ravel() == 1, :]  # Take only positive samples\n",
    "\n",
    "M_train = X_train.shape[0]\n",
    "M_val = X_val.shape[0]\n",
    "\n",
    "# Model Parameters\n",
    "k = 50\n",
    "embeddings_lambda = 0\n",
    "model = RESCAL(n_e=n_e, n_r=n_r, k=k, lam=embeddings_lambda, gpu= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-1\n",
      "----------------\n",
      "Iter-0; loss: 0.6914; train_auc: 0.6070; val_auc: 0.4883; val_loss: 0.6934; time per batch: 0.00s\n",
      "Epoch-2\n",
      "----------------\n",
      "Iter-0; loss: 0.6912; train_auc: 0.6281; val_auc: 0.4914; val_loss: 0.6934; time per batch: 0.00s\n",
      "Epoch-3\n",
      "----------------\n",
      "Iter-0; loss: 0.6896; train_auc: 0.6931; val_auc: 0.4973; val_loss: 0.6933; time per batch: 0.01s\n",
      "Epoch-4\n",
      "----------------\n",
      "Iter-0; loss: 0.6905; train_auc: 0.6393; val_auc: 0.5082; val_loss: 0.6930; time per batch: 0.01s\n",
      "Epoch-5\n",
      "----------------\n",
      "Iter-0; loss: 0.6890; train_auc: 0.7114; val_auc: 0.5217; val_loss: 0.6928; time per batch: 0.01s\n",
      "Epoch-6\n",
      "----------------\n",
      "Iter-0; loss: 0.6884; train_auc: 0.7268; val_auc: 0.5437; val_loss: 0.6923; time per batch: 0.01s\n",
      "Epoch-7\n",
      "----------------\n",
      "Iter-0; loss: 0.6879; train_auc: 0.7385; val_auc: 0.5737; val_loss: 0.6917; time per batch: 0.01s\n",
      "Epoch-8\n",
      "----------------\n",
      "Iter-0; loss: 0.6857; train_auc: 0.8075; val_auc: 0.6146; val_loss: 0.6908; time per batch: 0.01s\n",
      "Epoch-9\n",
      "----------------\n",
      "Iter-0; loss: 0.6838; train_auc: 0.8465; val_auc: 0.6649; val_loss: 0.6895; time per batch: 0.01s\n",
      "Epoch-10\n",
      "----------------\n",
      "Iter-0; loss: 0.6827; train_auc: 0.8421; val_auc: 0.7251; val_loss: 0.6876; time per batch: 0.01s\n",
      "Epoch-11\n",
      "----------------\n",
      "Iter-0; loss: 0.6810; train_auc: 0.8351; val_auc: 0.7861; val_loss: 0.6851; time per batch: 0.01s\n",
      "Epoch-12\n",
      "----------------\n",
      "Iter-0; loss: 0.6744; train_auc: 0.9011; val_auc: 0.8432; val_loss: 0.6815; time per batch: 0.00s\n",
      "Epoch-13\n",
      "----------------\n",
      "Iter-0; loss: 0.6749; train_auc: 0.8715; val_auc: 0.8845; val_loss: 0.6767; time per batch: 0.00s\n",
      "Epoch-14\n",
      "----------------\n",
      "Iter-0; loss: 0.6663; train_auc: 0.8796; val_auc: 0.9093; val_loss: 0.6701; time per batch: 0.00s\n",
      "Epoch-15\n",
      "----------------\n",
      "Iter-0; loss: 0.6600; train_auc: 0.8710; val_auc: 0.9190; val_loss: 0.6615; time per batch: 0.01s\n",
      "Epoch-16\n",
      "----------------\n",
      "Iter-0; loss: 0.6558; train_auc: 0.8449; val_auc: 0.9208; val_loss: 0.6510; time per batch: 0.01s\n",
      "Epoch-17\n",
      "----------------\n",
      "Iter-0; loss: 0.6410; train_auc: 0.8449; val_auc: 0.9188; val_loss: 0.6388; time per batch: 0.00s\n",
      "Epoch-18\n",
      "----------------\n",
      "Iter-0; loss: 0.6183; train_auc: 0.9138; val_auc: 0.9156; val_loss: 0.6258; time per batch: 0.00s\n",
      "Epoch-19\n",
      "----------------\n",
      "Iter-0; loss: 0.6040; train_auc: 0.9029; val_auc: 0.9135; val_loss: 0.6130; time per batch: 0.01s\n",
      "Epoch-20\n",
      "----------------\n",
      "Iter-0; loss: 0.6105; train_auc: 0.8502; val_auc: 0.9115; val_loss: 0.6016; time per batch: 0.01s\n"
     ]
    }
   ],
   "source": [
    "normalize_embed = True\n",
    "C = 10 # Negative Samples\n",
    "# Optimizer Initialization\n",
    "nepoch = 20\n",
    "lr = 0.1\n",
    "lr_decay_every = 20\n",
    "solver = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "n_epoch = nepoch\n",
    "mb_size = 100  # 2x with negative sampling\n",
    "print_every = 9999\n",
    "# Begin training\n",
    "for epoch in range(n_epoch):\n",
    "    print('Epoch-{}'.format(epoch+1))\n",
    "    print('----------------')\n",
    "    it = 0\n",
    "    # Shuffle and chunk data into minibatches\n",
    "    mb_iter = get_minibatches(X_train, mb_size, shuffle=True)\n",
    "\n",
    "    # Anneal learning rate\n",
    "    lr = lr * (0.5 ** (epoch // lr_decay_every))\n",
    "    for param_group in solver.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    for X_mb in mb_iter:\n",
    "        start = time()\n",
    "\n",
    "        # Build batch with negative sampling\n",
    "        m = X_mb.shape[0]\n",
    "        # C x M negative samples\n",
    "        X_neg_mb = sample_negatives(X_mb, n_e)\n",
    "        X_train_mb = np.vstack([X_mb, X_neg_mb])\n",
    "\n",
    "        y_true_mb = np.vstack([np.ones([m, 1]), np.zeros([m, 1])])\n",
    "\n",
    "        # Training step\n",
    "        y = model.forward(X_train_mb)\n",
    "        loss = model.log_loss(y, y_true_mb, average=True)\n",
    "        \n",
    "        loss.backward()\n",
    "        solver.step()\n",
    "        solver.zero_grad()\n",
    "        if normalize_embed:\n",
    "            model.normalize_embeddings()\n",
    "\n",
    "        end = time()\n",
    "        # Training logs\n",
    "        if it % print_every == 0:\n",
    "            # Training auc\n",
    "            pred = model.predict(X_train_mb, sigmoid=True)\n",
    "            train_acc = auc(pred, y_true_mb)\n",
    "            \n",
    "            # Per class accuracy\n",
    "            # pos_acc = accuracy(pred[:m], y_true_mb[:m])\n",
    "            # neg_acc = accuracy(pred[m:], y_true_mb[m:])\n",
    "\n",
    "            # Validation auc\n",
    "            y_pred_val = model.forward(X_val)\n",
    "            y_prob_val = F.sigmoid(y_pred_val)\n",
    "            \n",
    "            val_acc = auc(y_prob_val.data.numpy(), y_val)\n",
    "            # Validation loss\n",
    "            val_loss = model.log_loss(y_pred_val, y_val, True)\n",
    "\n",
    "            print('Iter-{}; loss: {:.4f}; train_auc: {:.4f}; val_auc: {:.4f}; val_loss: {:.4f}; time per batch: {:.2f}s'\n",
    "                    .format(it, loss.data[0], train_acc, val_acc, val_loss.data[0], end-start))\n",
    "\n",
    "        it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entity_embedding, relation_embedding = model.get_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Effect of learning rate and momentum on convergence\n",
    "\n",
    "For SGD change the value of learning rate and momentum and see its effect on convergence. FOr different value of learning rate and momentum do the plot of epochs vs loss (training as well as validation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "###### Your Code Here\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Latent Representation\n",
    "\n",
    "In this part we will use a very powerful visualization technique: T-SNE (t-Distributed stochastic neighbor embedding). T-SNE helps in visualizing embeddings in 2 or 3 dimensions. It is a nonlinear dimensionality reduction technique. It embeds high dimensional representation into lower dimension in such a way that similar objects are mapped to nearby points and distant objects are mapped to distant points. The algorithm is non linear and adapts to the underlying data, performing different transformations on different regions. It comes with a tueneable parameter perplexity which balances attention between local and global aspects of data.\n",
    "\n",
    "For further details on algorithm refer to: \n",
    "[Visualizing Data using t-SNE](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 103 nearest neighbors...\n",
      "[t-SNE] Indexed 104 samples in 0.004s...\n",
      "[t-SNE] Computed neighbors for 104 samples in 0.011s...\n",
      "[t-SNE] Computed conditional probabilities for sample 104 / 104\n",
      "[t-SNE] Mean sigma: 0.491476\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 52.534485\n",
      "[t-SNE] Error after 300 iterations: 0.523432\n",
      "[t-SNE] Computing 25 nearest neighbors...\n",
      "[t-SNE] Indexed 26 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 26 samples in 0.003s...\n",
      "[t-SNE] Computed conditional probabilities for sample 26 / 26\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 42.786060\n",
      "[t-SNE] Error after 300 iterations: 0.744218\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_entity = tsne.fit_transform(entity_embedding)\n",
    "tsne_relation = tsne.fit_transform(relation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrC8HCjMz6+v/A82i6xLAvInhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67d67591d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tsne_entity[:,0],tsne_entity[:,1])\n",
    "plt.xlabel('Latent Value-1')\n",
    "plt.ylabel('Latent Value-2')\n",
    "plt.title('Latent Representation Entities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67d6676978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tsne_relation[:,0],tsne_relation[:,1])\n",
    "plt.xlabel('Latent Value-1')\n",
    "plt.ylabel('Latent Value-2')\n",
    "plt.title('Latent Representation Relations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2 Parameter Tuning for RESCAL\n",
    "\n",
    "Split your validation data in two parts: validation and test. Proceed with following two tasks:\n",
    "\n",
    "a) After split you will end up with three datasets: training, validation and test. Use training and validation to learn a model and evaluate it on test set and report performance.\n",
    "\n",
    "b) Instead of running for maximum number of epochs define a convergence criterion monitoring your validation loss.\n",
    "\n",
    "c) Similar to previous exercise. Tune value of lambda on validation set and report performance on test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "###### Your Code Here\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3 Implement CP and TUCKER\n",
    "\n",
    "Adapt above RESCAL class and implement CP and TUCKER decomposition. Evaluate the embeddings on kinship dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "###### Your Code Here\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "a) http://pytorch.org/\n",
    "\n",
    "b) Knowledge Graph Models using pytorch awesome work by Agustinus Kristiadi https://github.com/wiseodd\n",
    "\n",
    "c) https://lvdmaaten.github.io/tsne/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
